{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gizelleguerra/genAI_demos/blob/main/Tivdak_chatbot_gpt_3_5_turbo_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir -p DATA/DORA;curl https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32022R2554 -o DATA/DORA/CELEX_32022R2554.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNi94c7jgW-M",
        "outputId": "39ad4af3-319a-48d3-f1af-a48325b1390a"
      },
      "id": "hNi94c7jgW-M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1458k    0 1458k    0     0  1536k      0 --:--:-- --:--:-- --:--:-- 1536k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p DATA/TIVDAK;curl https://docs.seagen.com/Tivdak_Full_Ltr_Master.pdf -o DATA/TIVDAK/tivdak.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmdYffmx0DrR",
        "outputId": "bff600d5-61e0-4ac5-da2b-a69efa1e069a"
      },
      "id": "GmdYffmx0DrR",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  452k  100  452k    0     0   465k      0 --:--:-- --:--:-- --:--:--  465k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q llama-index openai pypdf gradio loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrTpIfTBBjVt",
        "outputId": "6ba7e5db-ed41-4570-fd9b-9427169196b8"
      },
      "id": "VrTpIfTBBjVt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/626.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/626.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m481.3/626.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4921c412",
      "metadata": {
        "id": "4921c412"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import loguru\n",
        "\n",
        "import llama_index\n",
        "from llama_index import (\n",
        "    ListIndex, VectorStoreIndex, SimpleDirectoryReader, LLMPredictor,\n",
        "    ServiceContext,StorageContext, load_index_from_storage\n",
        ")\n",
        "from llama_index.response.notebook_utils import display_response\n",
        "from llama_index.llms import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "import logging, sys, os, json\n",
        "from pathlib import Path\n",
        "import openai\n",
        "from typing import List, Tuple, Dict, Union\n",
        "\n",
        "from loguru import logger\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nlAiAKd3YkM",
        "outputId": "be6df967-a134-4e09-eb33-b7bc1855ffc0"
      },
      "id": "2nlAiAKd3YkM",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4wRF-v24Xmx",
        "outputId": "8b57e35a-e094-4d97-e0a6-91618f3ed080"
      },
      "id": "w4wRF-v24Xmx",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261d923e",
      "metadata": {
        "id": "261d923e"
      },
      "outputs": [],
      "source": [
        "# cwd: Path = Path.cwd()\n",
        "# data_dir: Path = cwd / \"DATA\"; data_dir.mkdir(exist_ok=True, parents=True)\n",
        "# dora_dir: Path  = data_dir / \"DORA\"; dora_dir.mkdir(exist_ok=True, parents=True)\n",
        "# test_dir: Path = cwd / \"TEST\"; test_dir.mkdir(exist_ok=True, parents=True)\n",
        "# # Load TEST\n",
        "# documents: List = SimpleDirectoryReader(test_dir).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cwd: Path = Path.cwd()\n",
        "data_dir: Path = cwd / \"DATA\"; data_dir.mkdir(exist_ok=True, parents=True)\n",
        "drug_dir: Path  = data_dir / \"TIVDAK\"; drug_dir.mkdir(exist_ok=True, parents=True)\n",
        "# Load data\n",
        "documents: List = SimpleDirectoryReader(drug_dir).load_data()"
      ],
      "metadata": {
        "id": "bFJ9vlXe0i7j"
      },
      "id": "bFJ9vlXe0i7j",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_ai_key(env_path: Union[Path, str] = None) -> Tuple[bool, str]:\n",
        "  import json, os\n",
        "  from pathlib import Path\n",
        "\n",
        "  openai.api_key = None #clear previous key if exists\n",
        "  env_path: Path = Path(env_path).absolute() # in case env_path is passed as a str\n",
        "  if not env_path.is_file():\n",
        "    err: str = f\"File:{env_path} does not exist.\"\n",
        "  else:\n",
        "    try:\n",
        "      with open(env_path, \"r\") as f:\n",
        "          env_vars = json.load(f)\n",
        "      os.environ[\"OPENAI_API_KEY\"] = env_vars[\"OPENAI_API_KEY\"]\n",
        "      openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "      openai.Model.list() #test a random command on the openai API\n",
        "      err = None\n",
        "    except Exception as err:\n",
        "      logger.error(json.dumps(err))\n",
        "\n",
        "  return (True, \"ok\") if not err else (False, err)"
      ],
      "metadata": {
        "id": "cBPv_qUQDX6A"
      },
      "id": "cBPv_qUQDX6A",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cwd: Path = Path.cwd()\n",
        "env_path: Path = \"/content/drive/MyDrive/Colab Notebooks/openai.env\";\n",
        "print(set_open_ai_key(env_path)) # Tuple[bool, str]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2wcWk_QpclU",
        "outputId": "af8c9e5e-161b-41e5-e09c-44a7d4c6842c"
      },
      "id": "b2wcWk_QpclU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(True, 'ok')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0c635cdb",
      "metadata": {
        "id": "0c635cdb"
      },
      "outputs": [],
      "source": [
        "TEMPERATURE = 0\n",
        "\n",
        "llm: llama_index.llms.openai.OpenAI = OpenAI(\n",
        "    temperature=TEMPERATURE,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    max_tokens=300,\n",
        "    max_retries = 2)\n",
        "\n",
        "service_context: llama_index.indices.service_context.ServiceContext = (\n",
        "    ServiceContext.from_defaults(llm=llm)\n",
        "    )\n",
        "index: llama_index.indices.vector_store.base.VectorStoreIndex = (\n",
        "     VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b8ad1a2a",
      "metadata": {
        "id": "b8ad1a2a"
      },
      "outputs": [],
      "source": [
        "TEST = False\n",
        "\n",
        "persist_dir = (test_dir / \"storage\") if TEST else (cwd / 'storage')\n",
        "index.storage_context.persist(persist_dir=persist_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store and reload index from memory\n",
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "# rebuild storage context\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "index = load_index_from_storage(storage_context)"
      ],
      "metadata": {
        "id": "3apa1VTGNi9_"
      },
      "id": "3apa1VTGNi9_",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fa1d7242",
      "metadata": {
        "id": "fa1d7242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "be211ec5-d81d-42ad-c9da-e70434bc154d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Tivdak is used to treat adults with cervical cancer that has returned or spread to other parts of the body, and who have received chemotherapy that did not work or is no longer working."
          },
          "metadata": {}
        }
      ],
      "source": [
        "engine = index.as_chat_engine()#(chat_mode=\"openai\", verbose=True)\n",
        "q: str = 'Look only at the document. What is Tivdak used for?'\n",
        "response: llama_index.response.schema.Response = engine.query(q)\n",
        "display_response(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"You are an expert HR manager and the document is a resume. Does the candidate have experience with Sarbanes Oxley?\"\n",
        "display_response(engine.query(q))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "CIiQd4pBHhjk",
        "outputId": "2fabd6fb-83b0-45ae-c098-9644b55a31e6"
      },
      "id": "CIiQd4pBHhjk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Yes, the candidate does have experience with Sarbanes Oxley. They insured compliance for Sarbanes Oxley audits by establishing and maintaining an out-of-cycle capital approval process and authorized over $50M in requests yearly."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engine.query(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASdRaZlNKos8",
        "outputId": "e16a7934-4e54-4430-9217-c863bc3895f6"
      },
      "id": "ASdRaZlNKos8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response='Yes, the candidate does have experience with Sarbanes Oxley. They insured compliance for Sarbanes Oxley audits by establishing and maintaining an out-of-cycle capital approval process and authorized over $50M in requests yearly.', source_nodes=[], metadata=None)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGVYD2jdMZWU"
      },
      "id": "sGVYD2jdMZWU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.memory import ChatMemoryBuffer\n",
        "\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=1000)\n",
        "\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",\n",
        "    memory=memory,\n",
        "    system_prompt=\"\"\"You are a chatbot, able to have normal interactions.\n",
        "    You are an assistant to medical practitioners who is able to answer questions on drug prescribing guidelines.\n",
        "    \"\"\",\n",
        ")"
      ],
      "metadata": {
        "id": "JiZA2vnDL4Rw"
      },
      "id": "JiZA2vnDL4Rw",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#response = chat_engine.chat(\"Does the candidate have experience with Sarbanes Oxley?\");print(response)"
      ],
      "metadata": {
        "id": "TUs6Kq-LMacT"
      },
      "id": "TUs6Kq-LMacT",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(\"What kind of illness is Tivdak prescribed for?\");print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JA8jEDBpWN",
        "outputId": "7dffc47a-22fb-4557-9357-fa71961192aa"
      },
      "id": "v2JA8jEDBpWN",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TIVDAK is a prescription medicine used to treat adults with cervical cancer that has returned or has spread to other parts of the body, and who have received chemotherapy that did not work or is no longer working.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W52lgidPgph",
        "outputId": "7a8aeb5c-11db-4fa7-aee6-f5e431cac436"
      },
      "id": "9W52lgidPgph",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def respond_llm(message, chat_history):\n",
        "        bot_message = chat_engine.chat(message)\n",
        "        chat_history.append((message, bot_message.response))\n",
        "        return \"\", chat_history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(height=130) #just to fit the notebook\n",
        "    msg = gr.Textbox(label=\"Prompt\")\n",
        "    btn = gr.Button(\"Submit\")\n",
        "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
        "\n",
        "    btn.click(respond_llm, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Allows you to Press the <submit> button\n",
        "    msg.submit(respond_llm, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Allows you to Press enter to submit\n",
        "gr.close_all()\n",
        "demo.launch(debug=True)\n",
        "\n",
        "# to start a new chat, add a button that calls chat_engine.reset(). It should also call clear!"
      ],
      "metadata": {
        "id": "cwRK6DqlSRAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "8e492c90-acae-4402-e184-e1f3834c1ec7"
      },
      "id": "cwRK6DqlSRAd",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnoOrTQPNY9M"
      },
      "id": "vnoOrTQPNY9M",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}