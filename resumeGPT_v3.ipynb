{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gizelleguerra/genAI_demos/blob/main/resumeGPT_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "based on https://github.com/openai/openai-cookbook/tree/main/examples"
      ],
      "metadata": {
        "id": "ZQxWNb57WrWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7IB0HkdY6mZ",
        "outputId": "0017944e-e91b-4496-f99a-afd75f9e5063"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO  \n",
        "- Return a link to the full original resume instead of to chunks\n",
        "- Run experiments to find optimal chunking size of resume text\n",
        "- Figure out how to use Ada and Babbage to reduce costs\n",
        "- port to Azure Platform\n",
        "\n"
      ],
      "metadata": {
        "id": "58pU0G9FGWyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq loguru textract tiktoken openai azure-ai-ml mlflow azureml-sdk azureml-mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poRnH-oftTPb",
        "outputId": "6cec3a2e-fcd4-4c9f-b8b8-5d0ca1f727a9",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.0/814.0 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.3/224.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.2/136.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.7/245.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.7/245.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.4/779.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.9/965.9 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.4/245.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.7/152.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/31.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.18 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# before running this notebook, UPLOAD these files\n",
        "- openai.env\n",
        "- azure.env"
      ],
      "metadata": {
        "id": "gqPb-Nn776tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os,argparse,loguru, json, time, datetime, openai\n",
        "from pathlib import Path\n",
        "from loguru import logger"
      ],
      "metadata": {
        "id": "scY-DzUJquiS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbJv7J2Jk6Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_load_aml_env_vars(env_path=None):\n",
        "  import os, json\n",
        "  try:\n",
        "    with open(env_path, \"r\") as f:\n",
        "      env_vars = json.load(f)\n",
        "    os.environ[\"resource_group\"] = env_vars[\"resource_group\"]\n",
        "    os.environ[\"workspace_name\"] = env_vars[\"workspace_name\"]\n",
        "    os.environ[\"subscription_id\"] = env_vars[\"subscription_id\"]\n",
        "    if (os.getenv(\"resource_group\") and os.getenv(\"workspace_name\")\n",
        "    and os.getenv(\"subscription_id\")):\n",
        "      return True\n",
        "  except Exception as e:\n",
        "    logger.error(f\"{e}\")\n",
        "    return False"
      ],
      "metadata": {
        "id": "A1d_9gbMZ78f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_ai_key(env_path=None):\n",
        "  import json, os\n",
        "  from pathlib import Path\n",
        "  try:\n",
        "    with open(env_path, \"r\") as f:\n",
        "        env_vars = json.load(f)\n",
        "    os.environ[\"OPENAI_API_KEY\"] = env_vars[\"OPENAI_API_KEY\"]\n",
        "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "    openai.Model.list() #test a random command on the openai API\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    logger.error(f\"{e}\")\n",
        "  return False\n",
        "\n",
        "def test_set_open_ai_key(key_path=None):\n",
        "  openai.api_key = None #disconnect from api key if already registered\n",
        "  try:\n",
        "    set_open_ai_key(key_path)\n",
        "    openai.Model.list()\n",
        "    return True\n",
        "  except Exception as e:\n",
        "    logger.error(f\"{e}\")\n",
        "  return False\n"
      ],
      "metadata": {
        "id": "wwZXC6jUTLvh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_get_ml_client(env_path=None):\n",
        "  # this is a mix of sdk v1 and v2. Try to consolidate \n",
        "  import json, os, mlflow\n",
        "  from pathlib import Path\n",
        "  from azureml.core import Workspace \n",
        "  from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "  from azure.ai.ml import MLClient\n",
        "\n",
        "  if not env_path: return None\n",
        "\n",
        "  ws = Workspace.from_config(env_path)\n",
        "  tracking_uri = ws.get_mlflow_tracking_uri()\n",
        "  mlflow.set_tracking_uri(tracking_uri)\n",
        "\n",
        "  try:\n",
        "      credential = DefaultAzureCredential()\n",
        "  except Exception as ex:\n",
        "      # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not working\n",
        "      credential = InteractiveBrowserCredential()\n",
        "\n",
        "  is_loaded = maybe_load_aml_env_vars(env_path)\n",
        "  if is_loaded:\n",
        "    try:\n",
        "      ml_client = MLClient(\n",
        "          subscription_id=os.getenv(\"subscription_id\"),\n",
        "          resource_group_name=os.getenv(\"resource_group\"),\n",
        "          workspace_name=os.getenv(\"workspace_name\"),\n",
        "          credential=credential,\n",
        "      )\n",
        "      return ml_client\n",
        "    except Exception as e:\n",
        "      logger.error(f\"{e}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "zNLN8FKHzlAB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_setup_azure_env(azure_env_path=None):\n",
        "  # setup azure ml env if azure credentials are available.\n",
        "  if azure_env_path and azure_env_path.is_file() and maybe_load_aml_env_vars(azure_env_path):\n",
        "    ml_client = maybe_get_ml_client(azure_env_path)\n",
        "    if ml_client:\n",
        "      #do a random test to check that ml_client and mlflow are playing nicely together\n",
        "      import mlflow\n",
        "      experiment_name = 'mlflow-2'\n",
        "      mlflow.set_experiment(experiment_name)\n",
        "      from random import random\n",
        "\n",
        "      with mlflow.start_run() as mlflow_test_run:\n",
        "          mlflow.log_param(\"hello_param\", \"world\")\n",
        "          mlflow.log_metric(\"hello_metric2\", random())\n",
        "          os.system(f\"echo 'hello world2' > helloworld2.txt\")\n",
        "          mlflow.log_artifact(\"helloworld2.txt\")\n",
        "      return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "pzzqgJ9k9f34"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "#azure_env_path, openai_env_path, ml_client, openai.api_key = None, None, None , None\n",
        "openai_env_path, openai.api_key = None, None\n",
        "cwd = Path.cwd()\n",
        "# resume_path = cwd / \"Resumes\"\n",
        "# resume_path.mkdir(exist_ok=True)\n",
        "\n",
        "#azure_env_path = cwd / \"azure.env\" #uncomment if providing azure env\n",
        "openai_env_path = cwd/ \"drive/MyDrive/Colab Notebooks/openai.env\"\n",
        "#maybe_setup_azure_env(azure_env_path) #uncomment if providing azure env\n",
        "set_open_ai_key(openai_env_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCqHlEmz8CsZ",
        "outputId": "8139af03-41c7-4754-b7c3-badafcf0f0a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-05-16 18:04:03.879\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mset_open_ai_key\u001b[0m:\u001b[36m12\u001b[0m - \u001b[31m\u001b[1mExtra data: line 1 column 18 (char 17)\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# json read wasnt working so API key is here -- to do: FIX CODE ABOVE\n",
        "api_key = \"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\"\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "J0jN5RBrvArl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLIT SECTIONS\n",
        "source: Embedding_Wikipedia_articles_for_search.ipynb \n",
        "https://colab.research.google.com/drive/1EJMtCmF8jZc2Y-c1RaBxFSCTPcjzjJf4#scrollTo=TOVSYkDur9zA"
      ],
      "metadata": {
        "id": "5kUr4TQLdnRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll recursively split long sections into smaller sections.\n",
        "\n",
        "There's no perfect recipe for splitting text into sections.\n",
        "\n",
        "Some tradeoffs include:\n",
        "- Longer sections may be better for questions that require more context\n",
        "- Longer sections may be worse for retrieval, as they may have more topics muddled together\n",
        "- Shorter sections are better for reducing costs (which are proportional to the number of tokens)\n",
        "- Shorter sections allow more sections to be retrieved, which may help with recall\n",
        "- Overlapping sections may help prevent answers from being cut by section boundaries\n",
        "\n",
        "Here, we'll use a simple approach and limit sections to 1,000 tokens each by default, recursively halving any sections that are too long. To avoid cutting in the middle of useful sentences, we'll split along paragraph boundaries when possible."
      ],
      "metadata": {
        "id": "NVpjUKLwenCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extract text from pdf"
      ],
      "metadata": {
        "id": "pK5mrZ8PJ4L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textract, os, openai, tiktoken"
      ],
      "metadata": {
        "id": "fJ-sflJ77VjU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = 'gpt-3.5-turbo'  # only matters insofar as it selects which tokenizer to use\n",
        "\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "## TODO This needs more sophistication in the use of a delimiter\n",
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    \"\"\"Split a string in two, on a delimiter, trying to balance tokens on each side.\"\"\"\n",
        "    chunks = string.split(delimiter)\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  # no delimiter found\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  # no need to search for halfway point\n",
        "    else:\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        best_diff = halfway\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        return [left, right]\n",
        "\n",
        "\n",
        "def truncated_string(\n",
        "    string: str,\n",
        "    model: str,\n",
        "    max_tokens: int,\n",
        "    print_warning: bool = False,\n",
        "    TRUNCATION_WARNING_PERCENTAGE: float = 0.25\n",
        "\n",
        ") -> str:\n",
        "    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
        "    truncation_percentage = 1.0 - max_tokens*1.0 / len(encoded_string)\n",
        "    if print_warning and (len(encoded_string) > max_tokens) and (truncation_percentage > TRUNCATION_WARNING_PERCENTAGE):\n",
        "        logger.warning(f\"Warning: Truncated string from {len(encoded_string)} tokens to {max_tokens} tokens. \\nOriginalString:{string} \\n\")\n",
        "\n",
        "    return truncated_string"
      ],
      "metadata": {
        "id": "u3CZ5MwnnspR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], #legacy structure. \n",
        "    max_tokens: int = 1000,\n",
        "    model: str = GPT_MODEL,\n",
        "    max_recursion: int = 8,\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Split a subsection into a list of subsections, each with no more than max_tokens.\n",
        "    Each subsection is a tuple of parent titles [H1, H2, ...] and text (str).\n",
        "    \"\"\"\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    # if length is fine, return string\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    # if recursion hasn't found a split after X iterations, just truncate\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    # otherwise, split in half and recurse\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \", \"●\", \"•\", \":\", \";\"]:\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                # if either half is empty, retry with a more fine-grained delimiter\n",
        "                continue\n",
        "            else:\n",
        "                # recurse on each half\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1,\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    # otherwise no split was found, so just truncate (should be very rare)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        " "
      ],
      "metadata": {
        "id": "9JmwS-cZdlvp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4DdKtrgPweAr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load resumes from csv file made by pdf parser and then split and create embeddings.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Output/resume_books.csv\", usecols=[\"text\", \"source\"]);df.head()\n",
        "#df = pd.read_csv(\"/content/resume_books.csv\",usecols=[\"text\", \"source\"]);df.head()\n",
        "df = df.dropna()\n",
        "df.loc[:,\"name\"] = [f\"Name: {i}\" for i in df.index]\n",
        "df.loc[:,\"text2\"] = list(zip(df[\"name\"].to_list(), df[\"text\"].to_list()))\n",
        "df = df[[\"name\",\"text2\"]];df.head()\n",
        "df.to_csv(\"resume_books_v2.csv\")\n",
        "clean_texts = df[\"text2\"].to_list()\n",
        "clean_texts = [([x1],x2) for x1, x2 in clean_texts]"
      ],
      "metadata": {
        "id": "VAtkxHnlD6YQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_texts[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvhrram8ACkT",
        "outputId": "e75fa96a-a571-47aa-b5cb-9f41f518bb8e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Name: 2'],\n",
              " 'YEA JUN KIM  \\n(347) 533-0003  ■ yeajun.kim@nyu.edu  ■ linkedin.com/in/yeajun -kim/ \\nEDUCATION  \\nNEW YORK  UNIVERSITY  \\nThe Courant Institute of Mathematical Sciences  \\nM.S.  in Mathematics  in Finance  (Dec 2021  – Dec 2022 ) New York, NY  \\n• Coursework: Dynamic asset pricing, active portfolio management, market microstructure, advanced topics in \\nequity derivatives, time series analysis, advanced statistical inference  \\nNEW YORK  UNIVERSITY  \\nB.A. in Mathematics, Minor in Business Studies  (Sep 2014 – Dec 2021 ) New York, NY  \\n• Graduate Coursework:  Stochastic calculus, risk and portfolio management , financial securities and markets, Black \\nScholes, computing in finance, Monte Carlo simulation, data driven modeling, machine learning  \\n• Coursework:  Regression, mathematical statistics, PDEs, probability theory, numerical analysis, OOP, data \\nstructure, economics, financial accounting, information system, operations management  \\nEXPERIENCE  \\nHYPHEN  \\nQuantitative Analyst Intern  (May 2022 – Aug 2022 ) New York, NY  \\n• Constructed granular portfolios grouped by region and industry, using stocks from  MSCI ACWI Index ; screened \\nportfolios to satisfy rules of Islamic compliance  \\n• Implemented multivariable regression  to predict  U.S.  GDP and CPI; constructed point -in-time data  with vintage data  \\n• Conducted research on applications of  PCA to forecast correlations of multiple  assets \\n• Analyzed  auto- regressive factor model used to unsmooth and predict returns in private markets  \\n• Preprocess ed and handled various  time-series asset  data from multiple databases, such as Bloomberg, Factset  \\nMCC ECONOMICS & FINANCE  \\nFinance Intern (Nov 2020 – Feb 2021 ) London, UK  (remote ) \\n• Implemented beta estimation for UK energy companies using OLS, rolling OLS, and GARCH models; visualized \\ndata to enable competitive comparisons  \\n• Collaborated on financial analysis report on UK water companies’ performance  \\n• Constructed case studies on strategic planning as well as identifying and assessing financial risk  \\n• Researched a nd spot -checked gas companies’ financial reports for publications  \\nKOREA NATIONAL POLICE AGENCY  \\nSergeant , Analytical  Assistan t, Public Relations  (Aug 2015 – May 2017 ) Daegu, Korea  \\n• Conducted research on policing trends;  measured public reputation of national police; monitored media  \\n• Earned commissioner’s commendation;  for being #1 military police officer in public relations department  \\n• Led and represented team of 16 administrative police officers as squad leader  \\nPROJECTS  \\nMomentum Investment Strategy o n Cryptocurrency Portfolio (May 2021 – Aug 2021)  \\n• Constructed dynamic momentum strategy portfolio based on cryptocurrencies’ previous daily returns  \\n• Selected cryptocurrencies based on their market capitalization and daily traded volumes; predicted their price trends \\nby using divergence analysis  \\n• Set up specific indicators to decide when to stop loss or take profit; generated 16% returns  \\nKimchi Premium Trading Strategy (Feb 2021 – Mar 2021)  \\n• Implemented long/short trading s trategy using Kimchi Premium to determine price gap among cryptocurrencies in \\nSouth Korean Exchange and those outside Korea   \\n• Researched premium movements and constantly monitored premium rates for major cryptocurrencies  \\n• Constructed strategies for different  scenarios (e.g., when premium is high or low)  \\nEquity -Interest  Rate Hybrid Option Pricing (Nov 2020 – Dec 2020)  \\n• Designed option pricing model using geometric Brownian motion quantoed stock; also, Ho -Lee models that \\nsimulated LIBOR  \\n• Used two -factor Monte Carlo simulation to conduct time -dependent simulation of stocks and interest rates  \\nCOMPUTATIONAL SKILLS /OTHER  \\nProgramming Languages : Java, Python, MATLAB, R, SQL  \\nLanguage s: Korean  (native) , English  (fluent)  \\n ')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_texts[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr_sTS7D_nkP",
        "outputId": "964328c2-ab3d-487d-cca5-99d748ec64cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Name: 191'],\n",
              " 'MICHELLE L. DEMOTTE  \\nBronx, NY 10458  | (203) -241-330 1 | mdemotte@fordham.edu | www.linkedin.com/in/michelle -demotte   \\n  \\nEDUCATION  \\nFordham University, Gabelli School of Business           Bronx, New York  \\nBachelor of Sc ience in Business Administration , Major in Finance     September 2022  – May 2024  \\nProject:  Gabelli School of Business Consulting Cup Challenge  (2022)  \\n• Collaborat ing with a five -person team to develop a thorough financial and strategic analysis of Nordstrom  by \\nidentifying challenges, analyzing previous financial reports, and developing a marketing/implementation strategy   \\n \\nWestern Connecticut State University, Ancell College of Business             Danbury, Connecticut  \\nKathwari Honors Program ,           September 2021 - May 202 2 \\nGPA:  3.93/4.0, Dean’s List               \\n \\nSacred Heart University , Thomas More Honors Program              Fairfield, Connecticut  \\nGPA: 3.86/4.0, Dean’s List           September 2020 - May 2021  \\n \\nEXPERIENCE  \\nBrand Ambassador                  Danbury, Connecticut  \\nAerie                       August 2021 – Present  \\n• Ensured safe and accurate transfer of depository documents including witnessing, verifying, and transporting cash \\n• Supported  management and completed  tasks such as shipment, post -season transfers, and floor set  as well as \\ncashiering activities including purchases, returns, and exchanges in keeping with store policies \\n• Amplified guests’ experiences  with superior custome r service skills and professionalism  \\n \\nHome Delivery Shopper                      Danbury, Connecticut  \\nStop and Shop                     May 2020 - June 2021  \\n• Adapted to ever -changing COVID guidelines while performing fast -paced and time -sensitive  tasks  \\n• Initiated a leadership position t o support and uplift coworkers and increase workplace productivity \\n• Assembled grocery orders with timeliness and accuracy while exceeding the hourly fulfillment expectation  \\n Childcare Provider                             Brewster, New York  \\nSelf-employed              September 2018  – September 2022  \\n• Developed  and maintained accurate payroll documents stating reimbursements, credit, and payment schedules  \\n• Cultivated  lifelong relationships with 2  girls and completed daily  household duties thoughtfully \\n• Communicated clearly on a weekly basis about satisfying and exceeding family expectations and needs  \\n \\nVOLUNTEER EXPERIENCE  \\nTails of Courage                                Danbury, Connecticut  \\nFounder  and President , Volunteer         September 2018 - May 2019  \\n• Pioneered a Tails of Courage high school club with the corresponding local animal shelter  \\n• Collected and hand-deliver ed supplies including hundreds of dollars’ worth  of cash donations to the shelter  \\n• Organized  and oversaw bake sales, Chipotle fundraisers, and school -wide collections for materials and funding  \\n \\nSacred Heart University Journey                 Fairfield, Connecticut \\nVolunteer                                     Summer 2018, 2019  \\n• Centralized efforts to support lo cal gardens, housing developments, and communities in the greater Bridgeport area  \\n• Assessed community needs and developed solutions followed by insightful reflection in small group settings  \\n \\nACTIVITIES/INTERESTS  \\nSkills: Advanced Microsoft Excel, PowerPoint, Word, and Outlook \\nRelevant Coursework: Financial Accounting, Information Systems, Statistical Decision Making, Business Statistics  \\nInterests: Cooking, self-improvement, spending time outside, diversity, Minecraft, and traveling  ')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split resumes into chunks. Small chunks probably better when searching for skills? \n",
        "# maybe even shrink to individual sentences\n",
        "MAX_TOKENS = 50\n",
        "resume_strings = []\n",
        "for section in clean_texts:\n",
        "    resume_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "\n",
        "print(f\"{len(clean_texts)} resumes split into {len(resume_strings)} strings.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOlixxaYpCRC",
        "outputId": "1554c30c-d76c-43e5-e9ff-af3f33bfa4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191 resumes split into 4418 strings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_strings[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsriC0x-_x5N",
        "outputId": "90b00a31-cd41-460b-c109-b08f6681c617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name: 191\\n\\n \\nSacred Heart University Journey                 Fairfield, Connecticut \\nVolunteer                                     Summer 2018, 2019  ',\n",
              " 'Name: 191\\n\\n• Centralized efforts to support lo cal gardens, housing developments, and communities in the greater Bridgeport area  ',\n",
              " 'Name: 191\\n\\n• Assessed community needs and developed solutions followed by insightful reflection in small group settings  \\n \\nACTIVITIES/INTERESTS  ',\n",
              " 'Name: 191\\n\\nSkills: Advanced Microsoft Excel, PowerPoint, Word, and Outlook \\nRelevant Coursework: Financial Accounting, Information Systems, Statistical Decision Making, Business Statistics  ',\n",
              " 'Name: 191\\n\\nInterests: Cooking, self-improvement, spending time outside, diversity, Minecraft, and traveling  ']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# calculate embeddings and store in dataframe"
      ],
      "metadata": {
        "id": "Izi2RX_O1u0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # OpenAI's best embeddings as of Apr 2023\n",
        "MAX_BATCH_SIZE = 1000 # you can submit up to 2048 embedding inputs per request\n",
        "NUMBER_OF_STRINGS_TO_EMBED = len(resume_strings)\n",
        "\n",
        "if NUMBER_OF_STRINGS_TO_EMBED < MAX_BATCH_SIZE:\n",
        "  BATCH_SIZE = NUMBER_OF_STRINGS_TO_EMBED\n",
        "else: \n",
        "  BATCH_SIZE = MAX_BATCH_SIZE \n",
        "\n",
        "embeddings = []\n",
        "for batch_start in range(0, NUMBER_OF_STRINGS_TO_EMBED, BATCH_SIZE):\n",
        "    batch_end = batch_start + BATCH_SIZE\n",
        "    batch = resume_strings[batch_start:batch_end]\n",
        "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
        "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
        "    for i, be in enumerate(response[\"data\"]):\n",
        "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
        "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
        "    embeddings.extend(batch_embeddings)\n",
        "\n",
        "df = pd.DataFrame({\"text\": resume_strings, \"embedding\": embeddings})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hciff-Ul1t1B",
        "outputId": "dc7b9694-dcd6-4891-dd24-2317fcc729ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 to 999\n",
            "Batch 1000 to 1999\n",
            "Batch 2000 to 2999\n",
            "Batch 3000 to 3999\n",
            "Batch 4000 to 4999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store embeddings\n",
        "df.to_csv(\"embeddings_v2.csv\", index=False)"
      ],
      "metadata": {
        "id": "4WOqGbzmViZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8xSg_aVQK8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m9GE6wLE_iLh",
        "outputId": "b07e928c-8e7a-477c-9995-06350c95c45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0   Name: 0\\n\\n/content/resume_book_2023_courant.pdf   \n",
              "1              Name: 1\\n\\nRESUME BOOK\\nCLASS OF 2023   \n",
              "2  Name: 2\\n\\nRUIZE CHEN  \\n(585) 540-6418 // rui...   \n",
              "3  Name: 2\\n\\nExpected 12/23 NEW YORK UNIVERSITY ...   \n",
              "4  Name: 2\\n\\nM.S. in Mathematics in Finance \\n● ...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.00010535831097513437, -0.012883378192782402...  \n",
              "1  [-0.006130422931164503, -0.006197203416377306,...  \n",
              "2  [-0.0007784886402077973, 0.0017219326691702008...  \n",
              "3  [-0.013850468210875988, 0.01317818183451891, 0...  \n",
              "4  [-0.001279508345760405, -0.0063638705760240555...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54b3cf1e-929a-4313-b754-a36dc92dbb19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Name: 0\\n\\n/content/resume_book_2023_courant.pdf</td>\n",
              "      <td>[0.00010535831097513437, -0.012883378192782402...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Name: 1\\n\\nRESUME BOOK\\nCLASS OF 2023</td>\n",
              "      <td>[-0.006130422931164503, -0.006197203416377306,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Name: 2\\n\\nRUIZE CHEN  \\n(585) 540-6418 // rui...</td>\n",
              "      <td>[-0.0007784886402077973, 0.0017219326691702008...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Name: 2\\n\\nExpected 12/23 NEW YORK UNIVERSITY ...</td>\n",
              "      <td>[-0.013850468210875988, 0.01317818183451891, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Name: 2\\n\\nM.S. in Mathematics in Finance \\n● ...</td>\n",
              "      <td>[-0.001279508345760405, -0.0063638705760240555...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54b3cf1e-929a-4313-b754-a36dc92dbb19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54b3cf1e-929a-4313-b754-a36dc92dbb19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54b3cf1e-929a-4313-b754-a36dc92dbb19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgAJB8t3_hgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# search documents using query and text embeddings and and retrieve relevant consultant name from resume information using GPT"
      ],
      "metadata": {
        "id": "BMXkZkHWJE_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Search (once per query) - Given a user question, generate an embedding for the query from the OpenAI API\n",
        "1. Using the embeddings, rank the text sections by relevance to the query\n",
        "1. Ask (once per query)\n",
        "  1. Insert the question and the most relevant sections into a message to GPT\n",
        "  1. Return GPT's answer"
      ],
      "metadata": {
        "id": "ZF5Y0pILMG_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "Qwu5742ONHQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search function\n",
        "def strings_ranked_by_relatedness(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
        "    top_n: int = 3\n",
        ") -> tuple[list[str], list[float]]:\n",
        "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
        "    query_embedding_response = openai.Embedding.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "    )\n",
        "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
        "        for i, row in df.iterrows()\n",
        "    ]\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
        "    return strings[:top_n], relatednesses[:top_n]"
      ],
      "metadata": {
        "id": "DCLYKb9iUpab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_strings_ranked_by_relatedness(query, df, top_n=10):\n",
        "  strings, relatednesses = strings_ranked_by_relatedness(query, df, top_n)\n",
        "  for string, relatedness in zip(strings, relatednesses):\n",
        "      print(f\"{relatedness=:.3f}\")\n",
        "      display(string)"
      ],
      "metadata": {
        "id": "TIhPySTfWR0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"strong in math\"\n",
        "strings_ranked_by_relatedness(query, df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMpxgKyBJOHN",
        "outputId": "fa6ade2c-bcdb-4245-8a45-d3ee5a496ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('Name: 18\\n\\nin Mathematics and Applied Mathematics ',\n",
              "  'Name: 16\\n\\nin Mathematics in Finance ',\n",
              "  'Name: 23\\n\\nMath Department Grader \\n●\\nGraded homework for more than 300 students in upper-division courses including real analysis, \\nlinear algebra, abstract algebra, and probability \\n●'),\n",
              " (0.8197180259857161, 0.8182264010521288, 0.8150523976996884))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"understands pytorch\"\n",
        "strings_ranked_by_relatedness(query, df)"
      ],
      "metadata": {
        "id": "gCWRzTkWJN_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5078e0b2-9656-413f-80a9-97aa69986ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('Name: 4\\n\\nSklearn, Tensorflow), R, Java, C++\\nLanguages:\\nEnglish (fluent), Mandarin (native)\\nInterests:',\n",
              "  'Name: 6\\n\\n●\\nUsed natural language understanding; designed model that learned image generation from \\ntext data with 1M-word vocabulary, producing high-level generic sentence representations \\n●\\nImproved model by employing distributed text encoder conditioned with generative ',\n",
              "  'Name: 6\\n\\n08/16 - 02/17\\nINDIAN INSTITUTE OF TECHNOLOGY ROORKEE\\nRoorkee, India \\nText-Image Synthesis with Uni-Skip Vectors (Python, Deep Learning) '),\n",
              " (0.7835732057219097, 0.7830662985290144, 0.7830618617194605))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \" understands law\"\n",
        "strings_ranked_by_relatedness(query, df)"
      ],
      "metadata": {
        "id": "Cz-KCpslJN0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e164cc05-61f2-40de-dd40-d7e1411fc321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('Name: 81\\n\\nCompeted as a pre-trial attorney in a mock criminal law case \\n●\\nAnalyzed legal documents pertaining to the case and argued for the permittance of evidence ',\n",
              "  'Name: 161\\n\\nCompeted as a pre-trial attorney in a mock criminal law case \\n●\\nAnalyzed legal documents pertaining to the case and argued for the permittance of evidence ',\n",
              "  'Name: 110\\n\\n● Attended court hearings involving, commercial law, traffic violation, family law, and data breach cases  '),\n",
              " (0.8110228926750287, 0.8092794685151007, 0.8082582811210965))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \" azure databricks\"\n",
        "strings_ranked_by_relatedness(query, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN6Gyb11m65U",
        "outputId": "cacaaa0a-4722-45ce-a858-4092203ecafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('Name: 13\\n\\nwith Azure HDInsight; prepared data visualization for industry report\\n●',\n",
              "  'Name: 122\\n\\nTools: Jupyter Notebook, Tableau, Lucid Chart, Anaconda Navigator and Android Studio. Big Data and Cloud: Heroku, AWS',\n",
              "  'Name: 42\\n\\nTools: Jupyter Notebook, Tableau, Lucid Chart, Anaconda Navigator and Android Studio. Big Data and Cloud: Heroku, AWS'),\n",
              " (0.757380922555399, 0.7565015675875518, 0.7511625982697887))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ask\n",
        "\n",
        "With our database of resumes turned into vector embeddings, we can use the vector search function above to automatically retrieve relevant knowledge from the resumes and feed the query plus our knowledge base into GPT.\n",
        "\n",
        "Below, we define a function `ask` that:\n",
        "- Takes a user query\n",
        "- Searches for text relevant to the query\n",
        "- Stuffs that text into a message for GPT\n",
        "- Sends the message to GPT\n",
        "- Returns GPT's answer"
      ],
      "metadata": {
        "id": "MvV6e7bZno4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = 'gpt-3.5-turbo'\n",
        "def num_tokens(text: str, model: str = 'gpt-3.5-turbo') -> int:\n",
        "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "\n",
        "#using v1 search function\n",
        "def query_message(\n",
        "    query: str,\n",
        "    df: pd.DataFrame,\n",
        "    model: str,\n",
        "    token_budget: int\n",
        ") -> str:\n",
        "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
        "    logger.info(f\"Strings Found From Search\\n:{strings}\\n Relatednesses:{relatednesses}\\n\")\n",
        "    introduction = ' You are a Human Resources agent looking for skills in resumes'\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "    message = introduction\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nresume section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (\n",
        "            num_tokens(message + next_article + question, model=model)\n",
        "            > token_budget\n",
        "        ):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question\n",
        "\n",
        "@logger.catch\n",
        "def ask(\n",
        "    query: str,\n",
        "    df: pd.DataFrame = df,\n",
        "    model: str = GPT_MODEL,\n",
        "    token_budget: int = 4096 - 500,\n",
        "    print_message: bool = False,\n",
        ") -> str:\n",
        "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    logger.info(f\"{message}\")\n",
        "    content = \"Construct a list of Name fields from the documents given. Remove all duplicates from the list\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": content},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return response_message\n",
        "\n"
      ],
      "metadata": {
        "id": "HwIQfHT5ncvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask('who knows law')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "H4_3qNXCpLhV",
        "outputId": "f6d153de-e790-4660-f1d3-0b5ecf4f9bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-05-12 17:31:48.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_message\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mStrings Found From Search\n",
            ":('Name: 81\\n\\nCompeted as a pre-trial attorney in a mock criminal law case \\n●\\nAnalyzed legal documents pertaining to the case and argued for the permittance of evidence ', 'Name: 110\\n\\n● Attended court hearings involving, commercial law, traffic violation, family law, and data breach cases  ', 'Name: 161\\n\\nCompeted as a pre-trial attorney in a mock criminal law case \\n●\\nAnalyzed legal documents pertaining to the case and argued for the permittance of evidence ')\n",
            " Relatednesses:(0.7960334080871797, 0.7936805124322088, 0.7932960803294815)\n",
            "\u001b[0m\n",
            "\u001b[32m2023-05-12 17:31:48.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mask\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m You are a Human Resources agent looking for skills in resumes\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 81\n",
            "\n",
            "Competed as a pre-trial attorney in a mock criminal law case \n",
            "●\n",
            "Analyzed legal documents pertaining to the case and argued for the permittance of evidence \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 110\n",
            "\n",
            "● Attended court hearings involving, commercial law, traffic violation, family law, and data breach cases  \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 161\n",
            "\n",
            "Competed as a pre-trial attorney in a mock criminal law case \n",
            "●\n",
            "Analyzed legal documents pertaining to the case and argued for the permittance of evidence \n",
            "\"\"\"\n",
            "\n",
            "Question: who knows law\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Possible answer:\\n\\n- 81\\n- 161'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask('who majored in physics')"
      ],
      "metadata": {
        "id": "0Gvwt0TZpS-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "b0be056b-ea6b-42bf-b518-c9b185a1890e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-05-12 17:32:10.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_message\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mStrings Found From Search\n",
            ":('Name: 76\\n\\nBachelor of Science in Engineering Physics with Concentration in Mechanical Engineering\\nRelevant Coursework: Solidworks, AutoCAD, Machine Dynamics & Design, Mechanics of Materials, ', 'Name: 156\\n\\nBachelor of Science in Engineering Physics with Concentration in Mechanical Engineering\\nRelevant Coursework: Solidworks, AutoCAD, Machine Dynamics & Design, Mechanics of Materials, ', 'Name: 5\\n\\nB.S. in Physics and B.S. in Financial Math & Statistics \\n●\\nCoursework:\\nmultivariable calculus,\\nprobability and\\nstatistics,')\n",
            " Relatednesses:(0.8106379068250826, 0.8095400054922902, 0.8052200089651524)\n",
            "\u001b[0m\n",
            "\u001b[32m2023-05-12 17:32:10.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mask\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m You are a Human Resources agent looking for skills in resumes\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 76\n",
            "\n",
            "Bachelor of Science in Engineering Physics with Concentration in Mechanical Engineering\n",
            "Relevant Coursework: Solidworks, AutoCAD, Machine Dynamics & Design, Mechanics of Materials, \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 156\n",
            "\n",
            "Bachelor of Science in Engineering Physics with Concentration in Mechanical Engineering\n",
            "Relevant Coursework: Solidworks, AutoCAD, Machine Dynamics & Design, Mechanics of Materials, \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 5\n",
            "\n",
            "B.S. in Physics and B.S. in Financial Math & Statistics \n",
            "●\n",
            "Coursework:\n",
            "multivariable calculus,\n",
            "probability and\n",
            "statistics,\n",
            "\"\"\"\n",
            "\n",
            "Question: who majored in physics\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The following individuals majored in Physics:\\n- Resume section 3 (Name: 5)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY = 'who is a consultant'\n",
        "ask(QUERY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "PyVhRVwlX0Qk",
        "outputId": "e531832e-7bd6-4ce7-a992-62ca0851a7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-05-12 17:33:09.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_message\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mStrings Found From Search\n",
            ":('Name: 35\\n\\nPublic Consulting Group , Contact Tracer for New York State , Long Island Region , NY 12/2020 - 03/2022  ', 'Name: 115\\n\\nPublic Consulting Group , Contact Tracer for New York State , Long Island Region , NY 12/2020 - 03/2022  ', 'Name: 85\\n\\nAcquired industry-based knowledge from workshops regarding tax, consulting, audit, and advisory services and gained a \\ndeeper perspective on the consulting services industry\\nWE ARE ONE Campaign\\nSaco, ME ')\n",
            " Relatednesses:(0.7516799652320376, 0.7498786336834139, 0.7467068908859048)\n",
            "\u001b[0m\n",
            "\u001b[32m2023-05-12 17:33:09.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mask\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m You are a Human Resources agent looking for skills in resumes\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 35\n",
            "\n",
            "Public Consulting Group , Contact Tracer for New York State , Long Island Region , NY 12/2020 - 03/2022  \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 115\n",
            "\n",
            "Public Consulting Group , Contact Tracer for New York State , Long Island Region , NY 12/2020 - 03/2022  \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 85\n",
            "\n",
            "Acquired industry-based knowledge from workshops regarding tax, consulting, audit, and advisory services and gained a \n",
            "deeper perspective on the consulting services industry\n",
            "WE ARE ONE Campaign\n",
            "Saco, ME \n",
            "\"\"\"\n",
            "\n",
            "Question: who is a consultant\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It is not possible to determine who is a consultant based on the given resume sections as there is no clear indication of a specific person being referred to as a consultant.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUERY = 'who knows SAP'\n",
        "ask(QUERY)"
      ],
      "metadata": {
        "id": "PiKK-wOraNca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "2a0eb28e-0737-40d7-b03d-7166b029fbfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-05-12 17:34:19.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_message\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mStrings Found From Search\n",
            ":('Name: 3\\n\\nin largest global SAP S/4HANA ERP project at EY Singapore in 2019 for client, DyStar Group \\n●\\nConducted international localization workshops for franchises in 8 countries; communicated ', 'Name: 29\\n\\n12/20 - 02/21\\nACCENTURE\\nBeijing, China \\nTechnology Consulting Assistant (SAP) \\n●', 'Name: 29\\n\\nCollaborated with business planning and consolidation consultant to construct expense budget \\ntable in SAP; created 23 logical carding diagrams of cost allocation configuration rules ')\n",
            " Relatednesses:(0.7974384286051879, 0.7935589698321063, 0.7872619620330196)\n",
            "\u001b[0m\n",
            "\u001b[32m2023-05-12 17:34:19.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mask\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m You are a Human Resources agent looking for skills in resumes\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 3\n",
            "\n",
            "in largest global SAP S/4HANA ERP project at EY Singapore in 2019 for client, DyStar Group \n",
            "●\n",
            "Conducted international localization workshops for franchises in 8 countries; communicated \n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 29\n",
            "\n",
            "12/20 - 02/21\n",
            "ACCENTURE\n",
            "Beijing, China \n",
            "Technology Consulting Assistant (SAP) \n",
            "●\n",
            "\"\"\"\n",
            "\n",
            "resume section:\n",
            "\"\"\"\n",
            "Name: 29\n",
            "\n",
            "Collaborated with business planning and consolidation consultant to construct expense budget \n",
            "table in SAP; created 23 logical carding diagrams of cost allocation configuration rules \n",
            "\"\"\"\n",
            "\n",
            "Question: who knows SAP\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The first and third resumes mention SAP, indicating that those candidates have experience with SAP.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0uiiEhDlBw5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}